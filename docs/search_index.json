[
["index.html", "OHI Global Assessment Guide Chapter 1 Overview", " OHI Global Assessment Guide OHI Team 2019-03-11 Chapter 1 Overview The repositories used to calculate the global assessment are: ohiprep_v20?? Scripts and intermediate files used to prepare the data layers used by the OHI model. ohi-global Data layers, supplementary information, models, and scripts used to calculate the global scores. ohicore An R package that includes the core functions used in all assessments. See package description for more information. Table describing ohiprep_vYEAR contents (NOTE: suffix of repo name is the year of the assessment) folder description globalprep scripts used to prepare all goal, pressure, and resilience data layers (description of file organization) Reference handy reference materials used throughout the global assessmeent workflow Rmd templates, sourced files, and functions used throughout data preparation Table describing ohi-global contents (NOTE: this describes only the most relevant folders/files) folder description eez global models and data layers data layers used in the models (data are copied from ohiprep using paths from eez_layers_meta_data/layers_eez_base.csv) conf models and supplementary data used to calculate scores calculate_scores.R master script used to calculate scores scores.csv score output from calculate_scores.R (includes all score dimensions for each goal and country) eez_layers_meta_data | csv files describing data layers global_supplement | files used to create OHI methods document yearly_results | reporting on results of each year’s OHI assessment "],
["starting-a-new-year.html", "Chapter 2 Starting a new year 2.1 Review and organize relevant issues 2.2 Prepare the repositories! 2.3 Keeping track of layer progress", " Chapter 2 Starting a new year There are several steps to beginning a year’s assessment. This guide walks through the steps you will want to take. Each of the following steps is described in detail: Review and organize relevant github issues Prepare the repositories ohiprep ohi-global Keeping track of layer progress 2.1 Review and organize relevant issues Review the github::issues and create a list linking to the particular issues that might be useful in the year to come. This can include: references/discussion that may lead to improvements to goal models, pressures or resilience new datasets that are worth exploring potential newimprovements to ohicore ideas for reorganizing/cleaning repos etc. Create a new issue that organizes and links to these issues. This officially marks the start of the OHI assessment! (This is also a good time to close issues that are completed or no longer relevant) 2.2 Prepare the repositories! In preparation for the new assessment, you will need to prepare the repositories we use for the global assessment. For the ohiprep repository, you will actually copy the previous year’s assessment into a new repository with an updated name and delete the history. This helps to keep the size of the repository under control. For the ohi-global repository, you will update a couple files and perform a couple checks to make sure the scores do not change. ohicore will probably not need any changes. However, now is a good time to improve warning messages or add functions to improve analysis and visualization. This is also a good time to think about making organizational changes to the repositories. Sometimes an organizational scheme that worked well in the past doesn’t work as well over time. 2.2.1 ohiprep repository Create a copy of the most recent ohiprep repository and rename with the new assessment year. I use the following steps to do this: If you don’t have the most recent year’s repository, clone it to your local machine. For example, if the last completed assessment was in 2018, you would clone the https://github.com/OHI-Science/ohiprep_v2018. Here is one approach using RStudio: 2. Navigate to https://github.com/OHI-Science and create a new repository: Use the following parameters (but change the year in the repository name to match the current assessment year): 3. Copy the contents of the old ohiprep repository into the newly created repository. Open the ohiprep_v20?? project in RStudio, and navigate to the Shell: Make sure that you are in the old ohiprep working directory. This is indicated by the: C:\\Users\\Melanie\\github\\ohiprep_v2018 If you are not in the correct working directory use the cd command to navigate there. Type in the mirror command: 4. Navigate to the new repository on Github.com, https://github.com/OHI-Science/ohiprep_v20??.git and make sure the folders/files are there. Check that the default branch is “gh-pages” (and not the “master” branch). Clone the new repo to your local system (instructions in step 1) 6. Delete the commit history of the new repository. This gives us a clean slate to work from and keeps the repository from getting quite as big. I follow the general instructions from here. Make sure you are in the working directory of the new repository, and in the shell type the following: # Check out to a temporary branch: git checkout --orphan TEMP_BRANCH # Add all the files: git add -A # Commit the changes: git commit -am &quot;Initial commit&quot; # Delete the old branch: git branch -D gh-pages # Rename the temporary branch to master: git branch -m gh-pages # Finally, force update to our repository: git push -f origin gh-pages Navigate to the new repository on Github.com, https://github.com/OHI-Science/ohiprep_v20??.git and check whether there is only one commit. 8. Update README.md and delete unnecessary .Rproj files with the wrong year, commit, push. You are done….go have a cup of tea! 2.2.2 ohi-global The main files that get updated are: eez/conf/scenario_data_years.csv eez/calculate_scores.R 2.2.2.1 scenario_data_years.csv For each data layer, the scenario_data_years.csv associates the year the source data was collected or reported with the OHI assessment year. The data looks like this: In this case, the data layer for ao_access (access to artisanal fishing opportunities data used to calculate the score for the artisanal opportunities goal) goes from 2008 to the most current assessment year (not shown). The first OHI global assessment was in 2012 but the data goes to 2008 because five years of data are typically required to calculate trend. In this case, the 2012 trend was calculated using data from 2008 to 2012. The data year is 2013 for all assessment years because these particular data have never been updated. There is a helper script (eez_layers_meta_data/new_year_prep.R) that updates this file when embarking on a new assessment year. This script adds an additional assessment year to the eez/conf/scenario_data_years.csv. The data year is the same as the previous assessment year. As each data layer is added to update scores, the data year must be manually updated directly within the eez/conf/scenario_data_years.csv. 2.2.2.2 calculate_all.R The calculate_all.R script, located in the eez folder, is the main script used to calculate scores. This script creates objects used by ohicore functions, calls ohicore functions that calculate scores, and includes code to check results. This script needs to be updated for a new assessment year. Specfically, links to the ohiprep repository (step 2) and the most recent assessment year (step 3) must be updated. Once this script is updated, it is critical to walk through the entire script to make sure all the steps are working and there are no changes to the previous year’s scores. The ohicore::CheckLayers function will likely generate some warnings. The following warnings are expected and do not indicate a problem: Once the scores are generated, it is important to run the score_check function (step 10). For the scenario_year argument, be sure to provide the year of the most recent completed assessment: Once, this is run, check the html file that is created. This file will be in the eez/score_check folder with the name provided in the function (in the above example file_name = “check_2019_assess”) with the date it was generated. Ideally, this will be a very boring plot comprised of a series of yellow bars, indicating that nothing changed. Sadly, you may actually see something like this: At first glance, the changes to mariculture (and the corresponding food provision goal) and natural products and tourism is worrisome. If there have been no changes to models or data, these should be the same. However, I am somewhat reassured that all the changes are fairly small (&lt;1 point change in score). Regardless, these changes must be explained to convince ourselves that nothing is wrong. In the Git window, I notice that there were some changes to some reference point files. Further exploration reveals that adding an additional year changed the reference points of the mariculture and tourism and recreation goals. This change is fine because the reference points are calculated using all years of data. The small natural product goal changed for the similar reasons. I have now convinced myself that all is well. The final step of this process is to delete the eez/data_check folder. This will be created again at the start of the new assessment! Even though this folder is deleted, the files are preserved in the Git history. We don’t really want this, because these files will not be useful in the future and they are fairly large. This makes the ohi-global more bulky than it needs to be. Eventually, we will want to figure out how to delete these large files from Git history. But I wouldn’t bother until it becomes a problem (i.e., when the ohi-global repository starts taking a crazy long time to clone locally). 2.3 Keeping track of layer progress We use a Google Sheet to help us keep track of where we are in the process of preparing data for the OHI global. The following is part of the 2019 global assessemnt layers checklist: The main part of the checklist is created using code in ohi-global/eez_layers_meta_data/new_year_prep.R. However, the “Notes” are added in secondarily. The “Notes” can be used for many things during this process of conducting an assessment, but starting notes include information that is helpful while preparing the data. These notes are likely to change every year, but here is a place to start: Notes layers not updated, no new data ao_access, cw_trash_trend, eco_status, eco_trend, liv_status, liv_trend, fp_habitat, fp_mora, fp_mora_artisanal, g_mariculture, g_msi_gov, g_tourism, hab_coral_health, hab_coral_trend, hab_mangrove_health, hab_mangrove_trend, hab_saltmarsh_health, hab_saltmarsh_trend, hab_seagrass_health, hab_seagrass_trend, hd_habitat, had_subtidal_hb, le_sector_weight, li_sector_evenness, np_blast, np_cyanide, po_trash, po_water, sp_alien, sp_alien_species not updated, considered static data hab_coral_extent, hab_mangrove_extent, hab_rockyreef_extent, hab_saltmarsh_extent, hab_seagrass_extent, hab_softbottom_extent, rgn_area, rgn_area_inland1km, rgn_area_offshore3nm, rgn_global, rgn_labesl, sp_alien, sp_alien_species, uninhabited not updated, updated in functions.R element_wts_cp_km2_x_protection, element_wts_cs_km2_x_storage, element_wts_hab_pres_abs generated with LSP data fp_mpa_coast, fp_mpa_eez, hd_mpa_coast, hd_mpa_eez generated with SPP data species_diversity_3nm, species_diversity_eez WGI data ss_wgi, wgi_all (pressure and resilience, inverse of one another) SPI data ss_spi, res_spi (pressure and resilience, inverse of one another) before doing this layer, run code in mar_prs_population cw_pathogen_trend layer generated by mariculture script sp_genetic This is also a good time to do a literature search (and review issues during the past year) to determine whether there are new data sources for the layers that aren’t updated because new source data is unavailable. "],
["data-prep.html", "Chapter 3 Data Prep 3.1 File organization 3.2 Starting a new data prep project 3.3 A typical data prep script 3.4 prep Rmd: 1. Summary 3.5 prep Rmd: 2. Updates 3.6 prep Rmd: 3. Data sources 3.7 prep Rmd: 4. Set up 3.8 prep Rmd: 5. Data prep 3.9 prep Rmd: 6. Gapfilling 3.10 prep Rmd: 7. Results check 3.11 prep Rmd: 8. Final run 3.12 Notes on parallel processing", " Chapter 3 Data Prep All data layers are prepared in the ohiprep_v20?? repository. Spend some time researching the data prior to launching into the coding in R. I look over the files in the dataprep folder on Github, as well as the Mazu folder that contains the raw data. I research the specific data layers I will be working on and the goals/pressures/resilience dimensions they are used to calculate. I typically start in the methods document. I also research the source data, looking over websites, reports, and published papers. In regard to preparing the data, the best approach is to prepare the layer or layers within a single Rmd script and then update the OHI scores one layer at a time. This approach makes it much easier to identify and track potential errors. This section will discuss: 1. File organization 2. Starting a new data prep project 3. Anatomy of a typical data prep script 4. Notes on parallel processing 3.1 File organization 3.1.1 Saving external data In almost all cases, OHI data comes from other institutions. We save these data to the NCEAS private server (Mazu) because we do not want to be responsible for serving other people’s data. These data are saved to Mazu: git-annex/globalprep/_raw_data in a folder that is labeled with an abbreviated version of the datasource (Figure 1). The data is saved to a folder describing the year the data was downloaded (e.g., d2015, d2016). Figure 1: Location of raw data saved to Mazu. Every raw data folder should have a README.md (keep the caps so it is consistent and easy to see). *Note we are using .md rather than .txt even for READMEs on Mazu. Each README should include the following (template): Detailed source information. For example: full paper citation and link for publication Link to online data source Full email history with data provider If it was downloaded online, provided written and visual instructions so that the reader can mimic your same steps to get the same data. Include screenshots if possible! Version information for data Years included in the datatset Year the data was published Type of data included in the dataset (e.g., catch per species (tons) per country) Any other information that could possibly be useful to anyone 3.1.2 globalprep files All of the R scripts and metadata used to prepare the data, as well as the final data layers are saved in the Github ohiprep_v???? repository in the globalprep folder. The only data that will not be saved on Github are files that are too large or incompatible with Github (see below). Primary goal/component folder The folder should be named according to the OHI target (the goal or dimension that the data is used to calculate). For example the folder for the tourism and recreation goal would be called: globalprep/tr (see table below). These recommendations are flexible and should be modified as needed, for example goals can be combined in a single folder (e.g., spp_ico) or, there may be several folders for different components of a single goal (e.g. tr_sustainability and tr_tourists). target suggested folder name Artisanal Fishing Opportunity ao Carbon Storage cs Clean Waters cw Coastal Protection cp Coastal Livelihoods liv Coastal Economies eco Fisheries fis Habitats hab Iconic Species ico Lasting Special Places lsp Mariculture mar Natural Products np Species spp Tourism and Recreation tr Pressure prs_additional_pressure_id Resilience res_additional_resilience_id This folder will contain: a README.md that will link to the appropriate information pages on ohi-science.org The README.md should follow this template. Year-specific folders within the goal/component folder organize output by assessment year (v2015, v2016). Each of the assessment year folders should have: a README.md (see this template) a data_prep.R, or .Rmd that is well-documented. Here is the dataprep template. a series of folders to organize data that include: raw for ‘raw-ish’ type files that would not be on the server. This is typically for piecemeal raw data that we compile (e.g., U.S. State Department travel warnings), and not data we have downloaded from a single source (which would go on Mazu). In most cases, this folder will not be used. int for intermediate files (previously we’ve used tmp, working, or other naming conventions so this might not be entirely consistent). output for the final data layer that is used in the OHI toolbox. The final datasets (the ones stored in the output folder) will be preceeded by the target abbreviation followed by an underscore that provides a brief description of the data, e.g., tr_sustainability.csv). 3.1.3 Intermediate files that are too large for Github These files will be saved on Mazu, the internal server’s, globalprep folder. Our goal is to have everything (except for data obtained from other sources) stored on GitHub, but some files are too large or inappropriate for GitHub and must be stored on Mazu. Each of these files should be stored in a way that mirrors that on Github. If there is a need to make a duplicate folder on git-annex, it should have the same name as the folder used in GitHub. Store any intermediate or final output files that are too large for github in these folders. Keep the same subfolder structure. If you are working in spp_ico and have temporary rasters to store on Mazu, save them in a folder named int. Raw data should not be stored here. This should be stored in Mazu’s _raw_data folder 3.2 Starting a new data prep project 3.2.1 Prepare the dataprep folder In ohiprep_v20??/globalprep navigate to the folder that contains the files you will need to prepare the data. Select the most recent assessment year of data and copy/paste to create a new folder in the same location, changing the name to reflect the current assessment year. For example, if we are preparing data layers for the 2019 assessment for the artisanal opportunities goal, ao, we would copy the v2018 folder and name it v2019. Next, delete all unnecessary files, particularly the files in the raw, intermediate, and output folders! New versions of these data will be created in the updated data_prep script, and you want to be sure that this is indeed what happens. If there are data already in the folder it can be easy to overlook a mistake, such as not using the correct file path to save the data, etc.. Typically, you not delete the dataprep script/s and README. Youl will also want to preserve the folder structure. If in doubt, I delete the files and then copy them over as needed. For some goals, such as fisheries, there are lots and lots of files and it is very confusing. In these cases, I just copy the files as I need them. Once you have created and cleaned the new folder commit and push the updates! 3.2.2 Start an issue On Github create an issue for this dataprep project. Here you will document progress, report problems or concerns, pose questions, describe changes to code, and report on final results. Once the relevant data layers are created and incorporated into the OHI scores this issue will be closed. 3.2.3 Update the files Carefully walk through the data prep script/s and update as necessary. You will also need to update READMEs. As you check and update the scripts, don’t assume everything is correct. There could be changes to the source data that introduce errors (this often happens). We could have made a mistake somewhere. And, even if there aren’t any mistakes, there is usually room for improvement. Checking the dataprep scripts involves: Going through each line of code to understand what is happening. Each step of dplyr chains should be evaluated, rather than running the entire chain and assuming it is correct. Using functions such as summary, dim, length functions and figures to explore the data at different stages of preparation. Check the dimensions of the dataframe after each join or spread/collapse to ensure the length of the updated data makes sense. Check that the frequency of NA values seems reasonable, especially after joins and spread/collapse functions. And, if you gapfill missing values, make sure that you end up estimating all NA values. 3.3 A typical data prep script All data prep is performed in R or, preferrably, Rmd documents. Rmd is an ideal format because it seemlessly integrates code and documentation, can display figures, and the output provides a clean methods document. We have several shared practices for preparing data: Ideally Rmd/R files are used to download and save source datafiles, but this isn’t possible in most cases due to the format of the data. We put a large premium on documenting the steps used to prepare data! In many cases, the data preparation for a goal is performed in a single file. But, for more complex goals it is better to break the data preparation into multiple Rmd documents. If multiple Rmd documents are used, a README must describe what each Rmd document does, the input/outputs, and the order of processing. If a process is run multiple times, the code should be converted to a function and placed in folder labeled R or src. The here package, and here() function should be used control file paths. We use the tidyverse for tidying data A typical data prep script (or series of scripts) will include the following sections, which are described in more detail below: Summary: general description of the data prepared by the script Updates: updates to source data and/or methods from previous year Data sources: description of source data Set up: code chunk that loads relevant R packages and functions Data prep: code chunks for preparing the data, this is typically the bulk of the Rmd file Gapfilling: code chunks for estimating and documenting missing data Results check: code used to check results Final run: a final run of all the code after restarting R A generic data prep Rmd file is located on Github: github.com/OHI-Science/ohiprep_v2019/workflow/templates/generic_data_prep.Rmd 3.4 prep Rmd: 1. Summary This section describes the purpose of the script and the data layers that are generated. 3.5 prep Rmd: 2. Updates This sections describes all the updates to source data and/or methods since the previous year’s assessment. 3.6 prep Rmd: 3. Data sources This sections describes all data sources and may include: Reference: [citation for source data; website, literature, contact information. Version of data (if relevant).] Downloaded: [date downloaded or received] Description: [e.g., surface aragonite state] Native data resolution: [e.g., 1 degree, 30 m, country, etc.] Time range: [e.g., 1880-1899, monthly data provided for each year] Format: [e.g., NetCDF, Excel file] 3.7 prep Rmd: 4. Set up This code chunk is used to load packages, source functions, and set variables used throughout the analyses. 3.7.1 Packages The packages we load depend on the analyses, but we always use: * dplyr and tidyr: data wrangling tools (a cheatsheet: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) * here: controls file paths (https://github.com/jennybc/here_here) We often use the following for spatial analyses: * rgdal: tools for dealing with coordinate reference systems * sp: classes and methods for spatial data * sf: a new version of sp, providing a standardized way to encode spatial vector data * raster: reading, writing, manipulating, analyzing and modeling of gridded spatial data * fasterize: a better way to convert a shapefile to a raster file We often use the zoo package for time-series data. And, for parallel processing, typically used to perform spatial analyses, we use: * doParallel * foreach 3.7.2 common.R Nearly all scripts will source a common.R file. This file creates several objects that make it easier to conduct an OHI assessment. This includes: object description dir_M file path to Mazu mollCRS crs code for the mollweide coordinate refernce system we use in the global assessment regions_shape() A function to load a simple feature object called “regions” with polygons for land/eez/highseas/antarctica regions. The “regions” object uses the Mollweide coordinate reference system. ohi_rasters() function to load two rasters: global eez regions and ocean region rgn_data() function to load 2 dataframes describing global regions rgn_syns() function to load dataframe of region synonyms (used to convert country names to OHI regions) low_pop() function to load dataframe of regions with low and no human population UNgeorgn() function to load dataframe of UN sociopolitical regions, typically used to gapfill missing data To load the data in a data function: source(&#39;http://ohi-science.org/ohiprep_v2019/workflow/R/common.R&#39;) ## This file makes it easier to process data for the OHI global assessment ## by creating the following objects: ## ## * dir_M = identifies correct file path to Mazu (internal server) based on your operating system ## * mollCRS = the crs code for the mollweide coordinate reference system we use in the global assessment ## * regions_shape() = function to load global shapefile for land/eez/high seas/antarctica regions ## * ohi_rasters() = function to load two rasters: global eez regions and ocean region ## * region_data() = function to load 2 dataframes describing global regions ## * rgn_syns() = function to load dataframe of region synonyms (used to convert country names to OHI regions) ## * low_pop() = function to load dataframe of regions with low and no human population ## * UNgeorgn = function to load dataframe of UN geopolitical designations used to gapfill missing data # call the function to load the data, the message describes the available data: region_data() ## loads 2 dataframes: rgns_all and rgns_eez ## rgns_all = includes eez/high seas/antarctica regions, IDs correspond with region shapefile and raster ## rgns_eez = includes only eez regions head(rgns_all) ## rgn_type type_w_ant rgn_id rgn_ant_id rgn_name ## 1 eez eez 1 1 Cocos Islands ## 2 eez eez 10 10 Nauru ## 3 eez eez 100 100 Republique du Congo ## 4 eez eez 101 101 Namibia ## 5 eez eez 102 102 South Africa ## 6 eez eez 103 103 Sao Tome and Principe head(rgns_eez) ## rgn_id rgn_name eez_iso3 territory admin_rgn_id ## 1 1 Cocos Islands CCK yes 16 ## 2 2 Christmas Island CXR yes 16 ## 3 3 Norfolk Island NFK yes 16 ## 4 4 Macquarie Island AUS yes 16 ## 5 5 New Caledonia NCL yes 179 ## 6 6 Vanuatu VUT no 6 ## admin_country_name Notes ## 1 Australia ## 2 Australia ## 3 Australia ## 4 Australia ## 5 France ## 6 Vanuatu 3.7.2.1 metadata for common.R dir_M and mollCRS The following are the dir_M and mollCRS objects: ## dir_M describes the path to our internal server based on your computer&#39;s operating system ## NOTE: The following may be different on your operating system dir_M ## [1] &quot;/home/shares/ohi&quot; ## mollCRS is the code for the Mollweide coordinate reference system mollCRS ## CRS arguments: ## +proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs regions_shape The regions_shape function returns a simple feature object called “regions”. Regions is the master global shapefile that includes polygons for land, eez, high seas, and antarctica regions in the Mollweide coordinate reference system. Sometimes it is necessary to convert from a simple feature object to a shapefile object because some functions still do not work with simple feature objects, or, if the spatial file is modified, a saved shapefile may be desired. This is accomplished like this: regions_shape &lt;- as(regions, &quot;Spatial&quot;) The regions file with eez (dark blue), fao or high seas (light blue), and antarctica or CCAMLR (green) regions. The regions object is a simple feature multipolygon spatial object in the Mollweide coordinate reference system. There are 7 fields described in the table field data type description examples type_w_ant factor identifies all polygons as eez, fao (high seas), ccamlr (antarctica), or land eez (n=220), fao (15), eez-ccamlr (19), land (220), land-ccamlr (9), eez-disputed (1), land-disputed (1), eez-inland (3), land-noeez (38) rgn_type factor similar to type_w_ant, but does not specify eez/ccamlr and land/land-ccamlr regions eez (n=239), fao (15), land (229), eez-disputed (1), land-disputed (1), eez-inland (3), land-noeez (38) rgn_ant_id numeric region ids 1-250 country land and eez (these are the official global regions; some numbers are skipped); 255 disputed land and eez; 260-277 fao high seas; 301-337 (country land, no eez); 248100-288300 CCAMLR regions rgn_id numeric region ids; similar to rgn_ant_id, but Antartica/CCAMLR regions lumped as region 213 1-250 country land and eez (these are the official global regions; some numbers are skipped); 255 disputed land and eez; 260-277 fao high seas; 301-337 (country land, no eez) rgn_name character country/territory name e.g., Afghanistan, Belize, Prince Edward Islands rgn_key factor 3 letter identification code e.g., AFG, BEL area_km2 numeric area of region, km2 range of 1-30604795 ohi_rasters The ohi_rasters function returns two rasters, “zones” and “ocean”, both with ~1 km resolution and the mollweide coordinate reference system. The “zones” raster cell values are the OHI region ID. The raster cell values can be linked to the region names using the region_data() function, and the rgn_ant_id variable from rgns_all.csv. This raster is typically used to extract pressure data for the eez regions. The “ocean” raster identifies ocean cells with a value of 1, and other cells are NA [NOTE: There is something weird about this raster in that it lists the values as 0, 255 (min, max), when in fact there are only 1 and NA values! If you need to convince yourself of this, you can use the freq(ocean) function to identify all cell values.]. This raster file is typically used to mask the ocean regions for pressure data. region_data() The region_data function returns two dataframes, “rgns_all” and “rgns_eez”. The “rgns_all” dataframe includes data for the eez, fao, and ccamlr ocean regions. The IDs in rgn_ant_id correspond to the IDs in the zones raster. Once raster data are extracted for each region, the output is often aligned with the data in this dataframe. Metadata for rgns_all dataframe field | data type | description | examples ——— | —————- | ————— | —————————- rgn_type | factor | similar to type_w_ant, but does not specify eez/ccamlr and types | eez (n=239), fao (15) type_w_ant | factor | identifies all ocean polygons as eez, fao (high seas), ccamlr (antarctica) | eez (n=220), fao (15), eez-ccamlr (19) rgn_id | numeric | region ids; similar to rgn_ant_id, but Antartica/CCAMLR regions lumped as region 213 | 1-250 country eez (these are the official global regions; some numbers are skipped); 255 disputed eez; 260-277 fao high seas rgn_ant_id | numeric | region ids | 1-250 country eez (these are the official global regions; some numbers are skipped); 255 disputed eez; 260-277 fao high seas; 248100-288300 CCAMLR regions rgn_name | character | country/territory name | e.g., Afghanistan, Belize, Prince Edward Islands The “rgns_eez” dataframe includes data for the 220 OHI regions plus Antarctica (rgn_id 213). This file is used to make sure that all regions are included in dataprep files. It also includes data to indicate whether regions are territories. This can also be used for gapfilling (in some cases, it makes sense to assign territories the same value as their administrative country). Metadata for rgns_eez dataframe field | data type | description | examples ——— | ————— | ————— | —————————- rgn_id | numeric | official global regions (except Antarctica, 213) | 1-250 rgn_name | character | country/territory name | e.g., Afghanistan, Belize, Prince Edward Islands eez_iso3 | factor | 3 letter identification code | e.g., AFG, BEL territory | boolean | identifies whether the region is a territory | yes/no admin_rgn_id | numeric | administrative country rgn_id if a territory, otherwise the rgn_id | 1-250 admin_country_name | character | administrative country name if a territory, otherwise the country name | e.g., Afghanistan, Belize, Canada region_syns() Observed synonyms for each region, such that each region may have multiple synonyms. These data are used to convert outside data to the OHI region name and ID. This list is updated nearly everytime we run an assessment! Metadata for region_syns dataframe field | data type | description | examples ——— | —————- | ————— | —————————- rgn_id | numeric | region ids | 1-250 rgn_name | character | country/territory name | e.g., Federated State of Micronesia; Micronesia, FS; Micronesia (Federated States of) rgn_key | factor | 2-letter code for countries | e.g., FM eez_iso3 | factor | 3-letter code for countries | e.g., FSM rgn_typ | factor | status of region | disputed, landlocked, largescale (global, world); ohi_region low_pop() Includes data for 21 regions with 0 and low populations. These data are used to identify regions that should have NA values because the goal does not apply to regions with no/low populations (e.g., livelihoods and economies). Metadata for low_pop dataframe field | data type | description | examples ——— | ————— | ————— | —————————- rgn_id | numeric | region ids | 1-250 rgn_nam | character| country/territory name | e.g., Macquarie Island, Wake Island Southern_Island | boolean | indicates if region is a southern island | 1/0 Inhabited | boolean | indicates if region is uninhabited | boolean, 1/0 est_population | numeric | number of established people in region | 0-3000 UNgeorgn() Each global regions UN georegion based on social and geopolitical considerations. Metadata for UNgeorgn dataframe field | data type | description | examples ——— | ————— | ————— | —————————- rgn_id | numeric | region ids | 1-250 r0_label | factor | most inclusive category | World r1_label | factor | 7 classes | Africa (N=46), Americas (3), Asia (39), Europe (43), Latin America and the Caribbean (48), Oceana (34) Southern Islands (7) r2_label | factor | 22 classes | e.g., New Zealand, Melanesia rgn_label | character | global region name | e.g., Cocos Islands, Christmas Island Inhabited | boolean | indicates if region is uninhabited | boolean, 1/0 est_population | numeric | number of established people in region | 0-3000 3.8 prep Rmd: 5. Data prep We follow several coding practices when preparing our data: Code chunks are broken into manageable pieces and are proceeded by a description of what is being accomplished The code within a chunk is documented to make it easier to follow and to help prevent errors. For example, expected values and results are described to help prevent potential errors (e.g., check to see all values between 0-1, length should be 0, etc.). Run-on dplyr chains are avoided because they are impossible to follow and prone to error! Data is checked throughout the dataprep process (checking dimensions of data after joins, special attention to missing data, etc.) Intermediate data files are saved if they computationally take a long time to create or have information that could be useful in other aspects of the analysis. The here package is used to standardize file paths. The final output should be a dataframe that includes: rgn_id All 220 regions should be included in the final file! year This should include all years of data necessary to calculate scores for all scenario years, including trend. For some data layers the data has never been updated, in these cases, there is still a year column but it may only contain a single year. value This column will contain the calculated value for the data, and the column name will vary across datasets. In general, naming conventions should be consistently used every year, but feel free to modify the column name if you feel it could be improved. Just be sure to make the corresponding change to the “name_data_fld” in this file: https://github.com/OHI-Science/ohi-global/blob/draft/eez_layers_meta_data/layers_eez_base.csv. This file should be saved as a .csv file in an “output” folder. In general, the name of the file should be the same as the previous year. However, if you feel the file name can be improved, you will need to update the fn variable in this data file: https://github.com/OHI-Science/ohi-global/blob/draft/eez_layers_meta_data/layers_eez_base.csv 3.9 prep Rmd: 6. Gapfilling We make every effort to gapfill missing data. The only legitimate reason for a region to have an NA value is if the goal is not relevant to the region. For example, the livelihoods and economies goal is not relevant for an uninhabited island. We have a paper describing why and how we estimate missing data: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0160377. But the following is the short version. The first step to gapfilling missing data is to identify datasets that are predictive of the variable you are attempting to estimate and is also more complete. Here are some of the general approaches we use to estimate missing global data: Some mising data can be estimated from the original source. For example, if there are some missing years within a dataset, we can often estimate these values using a linear model of available data. For spatial raster data, we often estimate missing values using nearby raster cells. Secondary datasets can also be used to estimate mising values. For example, we gapfill some missing Social Progress Index values using World Governance Index data as a predictor. And, in many cases we use UN geopolitical data that classifies countries based on geopolitical and social variables to predict missing data. And, we often use multiple approaches to estimate missing values within a dataset. Our goal is to estimate missing data using the simplest model that best predicts the data. Given this, it is necessary to determine whether datasets and model terms actually predict missing data and to compare the performance of multiple models. Ideally cross-validation methods are used to evaluate how well the models predict missing data, otherwise models will appear to perform much better than they actually do. There is no point in having a model with many predictive variables and complex non-linear fits if it performs no better than using a simple mean of the existing data! Gapfilling steps are often mixed with the dataprep code. Once the gapfilling is done, we will save a dataset describing which data were gapfilled and the method. Every dataset should have a corresponding gapfilling dataset…even if there was no gapfilling. The gapfilling record is saved with the same name as the corresponding output data, but with a “_gf&quot; extension. The gapfilling dataset should mirror the corresponding dataset in regard to the number of rows and identifying columns (e.g., rgn_id, commodity, year, etc.). The gapfilling datset should include three additional columns that indicate the following: gapfilled: a zero or one value (or, NA if the value in the original data is NA) indicating whether the data was gapfilled or not. method: a short descriptor of the method that was used (this should be described more fully somewhere in the documentation). error: a numeric value describing the error around the estimate. This should be left blank if this was not determined (most of the time this will not be estimated). 3.10 prep Rmd: 7. Results check It is critical to check the final output data! Here are some of the ways we check data: Is each region included in the final data? Does the number of values for each region/year make sense (in most cases there should only be one value for each region/year) Does the ranking of the values make sense? Do the high and low performing regions seem reasonable? Do the number of NA values seem reasonable (ideally there will be none, unless the goal does not apply to that region) Does the range/distribution of values seem reasonable, for example, some outputs should range from 0-1. The functions I use most commonly to check data are: hist(), summary(), dim(), table() Because we calculate the global index every year, the most powerful way of checking our data is to compare the current data with last year’s data. In most cases, source data will remain the same from year to year (although some agencies will update previous data). Consequently, any changes will often reflect changes to the model and/or mistakes. For this comparison we typically compare the most recent shared year of data between the two assessments. The following code walks through this process using data calculated for the lasting special places goal. In this case, we will pretend we have just completed preparing the data for the 2018 assessment and we want to compare the results to the 2017 assessment. Here we focus on the data for the 3nm offshore region. library(dplyr) library(here) library(ggplot2) library(plotly) # want the region data from here: source(&#39;http://ohi-science.org/ohiprep_v2019/workflow/R/common.R&#39;) new &lt;- read.csv(here(&quot;globalprep/lsp/v2018/output/lsp_prot_area_offshore3nm.csv&quot;)) summary(new) old &lt;- read.csv(here(&quot;globalprep/lsp/v2017/output/lsp_prot_area_offshore3nm.csv&quot;)) summary(old) The most recent shared year between the two datasets is 2017, so this is the year that will be compared. The old and new values are plotted as a scatterplot, with a point for each region. We create an interactive plot and add a one-to-one line to make it easier to determine which regions have changed. Any changes in values will reflect either changes to the source data or changes to the data prep script. It is important to explore the reasons for these changes because it could reflect errors! # get region names region_data() head(rgns_eez) compare &lt;- new %&gt;% rename(a_prot_3nm_new = a_prot_3nm) %&gt;% left_join(old, by=c(&quot;rgn_id&quot;, &quot;year&quot;)) %&gt;% filter(year == 2017) %&gt;% left_join(rgns_eez, by=&quot;rgn_id&quot;) %&gt;% select(rgn_id, rgn_name, year, a_prot_3nm, a_prot_3nm_new) %&gt;% mutate(region=paste(rgn_id, rgn_name, sep = &quot;-&quot;)) summary(compare) compare_plot &lt;- ggplot(compare, aes(x=a_prot_3nm, y=a_prot_3nm_new, label=region)) + geom_point() + geom_abline(slope=1, intercept=0, color=&quot;red&quot;) ggplotly(compare_plot) In this case, the values for most regions remain the same from the 2017 to 2018 assessment, however, there are some changes. The biggest change was for Antarctica, which we can ignore because we do not calculate scores for Antarctica for the global assessment. However, there is also a fairly large change in the Greece data, and some smaller changes for some other regions. By carefully exploring the source data we found that these differences reflect updates to the source data. For example, a marine reserve may have been established in 2017, but weren’t yet incorporated into the World Database on Protected Areas. 3.11 prep Rmd: 8. Final run The final step is to commit and push all files. Then, close R and do NOT save the workspace image. The purpose of closing everything is to clear the memory of all data objects to make sure that the code still runs. This may be a problem if we change object names but fail to make necessary corresponding throughout the code. I typically close everything by opening another repository. Restart R and return to the ohiprep repo and rerun everything (except any really long processes). Check the following: Does all the code still run? Do you get the same results (check to see if output csv files are loaded to the Git window, this indicates that the data probably changed)? Review warnings Identify parts of the code you are unsure of, and have someone review 3.12 Notes on parallel processing Coming soon! "],
["updating-scores.html", "Chapter 4 Updating scores", " Chapter 4 Updating scores Need to add something here! "],
["finalizing-the-global-assessment.html", "Chapter 5 Finalizing the global assessment 5.1 Create results folder 5.2 Final score review 5.3 Methods document 5.4 Results document 5.5 Updates document 5.6 Upload to a repository", " Chapter 5 Finalizing the global assessment There are several steps after getting the scores to finalizing an assessment. This guide walks your through these steps. Each of the following steps is described in detail below: Create results folder Final score review Methods document Results document Updates document Update the website Finalize and create a “release” for repositories Upload to repository 5.1 Create results folder We summarize the results from each year’s assessment in the yearly_results/global20?? folder. After the OHI scores have been updated with the new data layers a global20?? folder should be created in the ohi-global/yearly_results folder, and populated with: an empty “data_check” and “Results” folder a copy of the README“,”Results_first_look.Rmd“,”Results/Supplement_Results.Rmd“, and”Results/functions&quot; from the previous year you may find other files from previous years to be useful as well, but only copy them as needed (many of the files were created to meet needs specific to a particular assessment year) The Results_first_look.Rmd creates an internal html document that provides our first look at the scores. This is mostly used internally to explore and check results. This script also does the following: copies the scores.csv from the eez folder to this (yearly_results/global20??) folder and appends the current date to the filename. This allows us to version control our data so we can keep better track of it. This is especially handy during the final stages of an assessment when there are lots of versions of the data flying around email and such! creates a user friendly version of the data called OHI_final_formattted_scores_date.csv. This is typically the version of data we provide to people. creates most of the data in the Results/data folder and figures in the Results/figures folder It will be necessary to carefully walk through the previous year’s version of the Results_first_look.Rmd file and make relevant updates as needed, such as: on ~ line 88 change: update_data = TRUE on ~ line 84 change the dateFile to the current date, e.g., dateFile = '2018-10-03' correct links: Data read through to correct references to scores/regions If there are any changes to the scores the Results_first_look.Rmd must be updated and rerun. 5.2 Final score review Once all the data layers have been updated we conduct a final review of the scores, which involves these steps: Update and disperse the Results_first_look.html to team members to review. Meeting with team members to discuss scores, document questions/concerns in a new Github issue. To address these concerns, review the data/code and, if necessary, update the scores with corrections to the data or code. These checks are performed via R/Rmd scripts in the yearly_results/global20??/data_check folder. The results from each check is also documented in the Github issue. Update and rerun the Results_first_look.Rmd as needed If necessary, we have a second meeting to discuss the updated scores (usually this isn’t necessary). 5.3 Methods document Every year we update a document describing the methods used to calculate the assessment (example methods document: https://raw.githack.com/OHI-Science/ohi-global/published/global_supplement/Supplement.htmlhttps://raw.githack.com/OHI-Science/ohi-global/published/global_supplement/Supplement.html). This file can be accessed from our OHI-science global webpage. The files used to create this document are located here: https://github.com/OHI-Science/ohi-global/tree/draft/global_supplement To maximize flexibility, we have broken our methods into component parts that can be used in multiple contexts. For example, the Rmd files that describe each data layer are incorporated into the official methods document and are also used to create a webpage describing the data layers. Previously, if we updated our methods we had to update both the methods document and the website, but with this approach we only have to make the change in one location. This helps keep our messaging more consistent. Table: A description of the files in the ohi-global/global_supplement repository folder/file name description updates Supplement.Rmd combines all components to create the final methods document No changes to this script are likely necessary, but this Rmd must be knitted when any components change (see description below) CombineLayers.R Combines all the layer Rmds located in the layers_info folder into a single Rmd file called layers_all.Rmd No changes to this script are likely necessary, but this R file must be run whenever there are changes to any of the data layer Rmds layers_all.Rmd Created by CombineLayers.R, includes a description of all data layers Created automatically when CombineLayers.R is run OHI.bib A .bib file of the OHI references (more on that below) Updated yearly BIBcorrect.R Corrects weirdness in the .bib file This probably will need to be updated yearly; this will be determined after reviewing the formatted citation list tables folder with datatables of 10 goal and 8 subgoals No changes likely necessary index_scores.Rmd description of OHI model for calculating index scores No changes likely necessary goal_model.Rmd description of OHI model for calculating goal scores No changes likely necessary trend.Rmd description of OHI model for calculating trend scores No changes likely necessary pressure.Rmd description of OHI model for calculating pressure scores No changes likely necessary resilience. Rmd description of OHI model for calculating resilience scores No changes likely necessary goal_descriptions folder individual Rmd files describing each goal/subgoal Minimal changes to some files may be necessary if the model or data used in a goal changes goal_descriptions_short folder individual Rmd files with a short description of each goal/subgoal Minimal changes to some files may be necessary if the model or data used in a goal changes layers_info folder individual Rmd files with descriptions of each data layer, filenames must match layer names in eez_layers_meta_data datatables Changes to some layers will probably be necessary, but most layers will require no changes figures folder figures displayed in the Supplement.html No changes likely necessary methods-in-ecology-and-evolution.csl instructions for displaying references no need to change unless a different way of displaying references is desired 5.3.1 Steps to updating methods document The methods document is created by knitting ohi-global/global_supplement/Supplement.Rmd. However, many preparations need to be made prior to knitting. 5.3.1.1 Step 1: Update eez_layers_meta_data The data tables in ohi-global/eez_layers_meta_data are used to create the methods document, and consequently must be fully up-to-date and accurate! This includes: layers_eez_base.csv, layers_eez_data_sources.csv, layers_eez_methods.csv, and layers_eez_targets.csv. Currently, the layers_eez_gapfill.csv is not used to create the methods document, but it is still a good idea to update this as well. For information about updating these datatables, see: Coming Soon! 5.3.1.2 Step 2: Update OHI.bib Make sure all references are included in the OHI Zotero library (see for more information: Coming Soon!). Then export the OHI library as a BibLaTeX file and replace the OHI.bib file in ohi-global/global_supplement with the updated file. We have noticed that some of the OHI.bib entries need to be modified to report correctly. For example, when the author of a report is an agency, such as the US State Depart, it will be reported as “Depart, US”. For this reason, we use the BIBcorrect.R file to correct and then overwrite the OHI.bib file. 5.3.1.3 Step 3: Update layers_info The layers_info folder includes an Rmd file for every data layer used to calculate the global OHI assessment. The files describe the general methods and data used to generate the layer. Ideally, these Rmd files do not include information that changes each year (e.g., final year of data used in analysis, links to data preparation files on Github, etc), so they can be used each year with minimal changes. Components that change every year should be included in tables, such as those in _ohi-global/eez_layers_meta_data. However, if there have been changes to the model or data used to generate a layer it will be necessary to update the corresponding Rmd file. After the Rmds have been updated it is necesary to run the CombineLayers.R file, which merges all the layer information into a single document, layers_all.Rmd. 5.3.1.4 Step 4: Review other files Review whether any of the other files require editing. There may be changes to the text to make it clearer, but otherwise, the following files are unlikely to change: There will be no changes to the following files: goal_model.Rmd, insex_scores.Rmd, pressure.Rmd, resilience.Rmd, or trend.Rmd, unless changes are made to the OHI models (which is unlikely). The Rmds describing the goal models in the goal_descriptions and goal_descriptions_short folders will only change if there have been changes to the goal model or data. Changes to the goal/subgoal descriptions in the “tables” folder are unlikely. 5.3.1.5 Step 5: Knit Supplement.Rmd Review the Supplement.Rmd document to update the assessment year (i.e., title at top, assessmentYear variable in this code chunk, update figure 3.1). Knit the file and review the html output. Make any necessary changes and repeat…seemingly endlessly until everything is correct. 5.4 Results document After producing the final scores, we create a document that describes the results of the assessment: https://raw.githack.com/OHI-Science/ohi-global/published/global2018/Results/Supplement_Results.html. This file can be accessed from our OHI-science global webpage. The file is created using this Rmd: ohi-global/yearly_results/global20??/Results/Supplment_Results.Rmd. It is critical to carefully step through this script and modify as needed; for example, the date of the radicalFile object must match the date appended to the csv file of scores created by Results_first_look.rmd (e.g., radicalFile = ‘2018-10-10’, ~line 92). And, of course, freely modify this script to reflect the data/figures you believe will be most useful to people. This could involve editing text, removing particular figures, adding figures, etc. NOTE: If there are any changes to the scores, it is important to run the Results_first_look.Rmd file prior to running this script. Many of the figures in the Supplement_Results document are actually generated by the Results_first_look.Rmd script. 5.5 Updates document 5.6 Upload to a repository One of the final steps of an assessment is submitting the final data (and related files) to a data repository. This makes the files publicly available and provides a DOI (digital object identifier, https://www.doi.org/) used to officially cite the data. We have been using the Knowledge Network for Biocomplexity, or KNB (https://knb.ecoinformatics.org/) as our data repository. An example of our data on KNB is here: https://knb.ecoinformatics.org/view/doi:10.5063/F12Z13R6 Signing into KNB requires an ORCID account. An ORCID account is obtained here: https://orcid.org/register. You will then make your way to https://knb.ecoinformatics.org/. Select the SIGN IN tab, and then “Sign in with ORCID”: Select the “Upload data”, and start adding files and information: The following is the information we used for the 2018 assessment, but please modify and improve as desired! 5.6.0.1 Overview Title: Global Ocean Health Index 2018 assessment Abstract: Scores from the 2018 global Ocean Health Index (OHI) assessment and accompanying data and models. The global Ocean Health Index assesses ocean health for 220 coastal countries and territories and has been conducted yearly since 2012. The Index describes how well we are sustainably managing 10 goals which represent the full suite of benefits that people want and need from the ocean. These goals include: artisanal fishing opportunity, biodiversity, carbon storage, clean waters, coastal livelihoods and economies, coastal protection, food provision, natural products, sense of place, and tourism and recreation. Each goal is given a score ranging from 0 to 100, and the full suite of goal scores are then averaged to obtain an overall index score for each region. Please see http://ohi-science.org/ for additional resources and information. Keywords: OHI, index, ocean 5.6.0.2 People OHI team (including the OHI Fellows) Contacts: If in doubt, put Benjamin Halpern 5.6.0.3 Dates First data is 2012. The later date is the year of the assessment. 5.6.0.4 Locations Short geographic description: Global country and territorial EEZ regions (N=220) Northwest coordinates: 90 -180 Southeast coordinates: -90 180 5.6.0.5 Taxa NA 5.6.0.6 Methods Step 1: See Methods.html file 5.6.0.7 Add Files Please use your judgment, but we included the following files in the global 2018 assessment: scores.csv: scores file that is created secondarily to include region names and expanded goal names. Methods.html: methods used to calculate the global OHI scores (this is created in the global_supplement folder in the ohi-global repository). Global_OHI_Results: Figures and tables of global results. This is currently an informal document, but I would like to improve this in future years. Zip files of the 3 repositories used to calculate the global OHI assessment: ohiprep, ohi-global, and ohicore. These files are downloaded from the “release” version of repository (this assumes you have already created the release). You navigate to the release by first going to the repository of interest and selecting “releases”: Then download the .zip option: Once all the information has been entered and the files uploaded to the KNB site you can obtain a link for your data. Navigate to “My data sets” and select the one you are working on from the list and copy the web address. Create an issue and provide the link so anyone who wants to review the information can do so. You can easily edit everything at this point! NOTE: At this point the data does not have an official DOI. Once everyone is satisfied with the content, you can officially “Publish with DOI”: The data now officially has a DOI, and you can mark this off your list of things to do! "]
]
